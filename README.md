# SwissAi Data Catalogue 

[THIS IS A TEST]

This repository organise the collection and curation of datasets for the SwissAi Initiative.

[![License: CC BY 4.0](https://img.shields.io/badge/License-CC_BY_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)
[![Slack](https://img.shields.io/badge/Slack-5A255B?style=flat-square&logo=slack&logoColor=white)](https://swissai-initiative.slack.com/join/shared_invite/TOBECOMPLETED/)

Do you know about an existing dataset or a (large) set of raw textual documents?      
Do not hesitate to contribute to the SwissAI data catalogue - it is as simple as opening an [issue](https://github.com/impresso/test-catalogue/issues/new/choose)!

We invite you to contribute two types of data record:
- A dataset record [\[Dataset Record Issue Template\]](https://github.com/impresso/test-catalogue/issues/new?assignees=&labels=&projects=&template=dataset_template.yml&title=%5BAdd+a+dataset+record%5D%3A+)
- A source record [\[Text Source Data Issue Template\]](https://github.com/impresso/test-catalogue/issues/new?assignees=&labels=&projects=&template=source_text_data_template.yml&title=%5BData+Entry+for+%28Row%29+Text+Data%5D%3A+)

[Overview](#overview)
[How to contribute](#how-to-contribute)
[Guidelines](#guidelines)

## Overview

[WIP]

We aim at collecting extensive information about datasets thus the record templates are quite long. Thanks in advance for your time!

There are two phases:
1. Dataset candidacy and assessment.
2. Dataset preparation

[schema]

[main priorities and principles]

## How to contribute
### How to contribute a dataset record
1. Please begin by carefully reading the [guidelines](#guidelines) below. 
2. Complete a dataset or source issue template and submit it.
3. A member of the SwissAi Data team will look at the issue, check if everything is complete and assess what next steps are necessary (dataset audit). If some information is missing, we may get back to you.
4. If everything is ok, the issue will be labelled as `dataset_candidate`. This labeling triggers the creation of a `.json` file for the record, and adds the dataset to the list in the section below (via a github action).
5. The dataset enters the preparation phase.

### How to contribute to a dataset preparation

(information of main steps here, how to contribute a labeller, a cleaner, etc. link to the adequate repo)

## Guidelines

### 1. Dataset or data source?
### 2. Generic information
### 3. Information about the dataset itself
### 4. Information about the data in the dataset

## Datasets
<!-- DATASET_LIST -->
* **zany-sea-dataset**: requires-copyright-clearance
* **brisk-durian-dataset**: ready-to-process
